# data-pipeline.yml
name: Data Pipeline

on:
  push:
    paths:
      - 'data/**'
      - 'src/data_processing/**'
  workflow_dispatch:

jobs:
  data-processing:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest

    - name: Run data preparation
      id: data-prep
      run: python main.py --prepare
      continue-on-error: false

    - name: Run data tests
      id: data-tests
      if: success()
      run: python -m pytest
      continue-on-error: false

    - name: Upload processed data
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: prepared-data
        path: prepared_data.joblib  # This is the source file to upload
        retention-days: 30

    - name: Process completion status
      if: always()
      run: |
        if [[ "${{ job.status }}" == "success" ]]; then
          echo "PIPELINE_STATUS=✅ Data pipeline completed successfully" >> $GITHUB_ENV
        else
          echo "PIPELINE_STATUS=❌ Data pipeline failed" >> $GITHUB_ENV
        fi
